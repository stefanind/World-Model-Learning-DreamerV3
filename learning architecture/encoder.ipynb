{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f8e0838",
   "metadata": {},
   "source": [
    "# Learning Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e96cc5b",
   "metadata": {},
   "source": [
    "The DreamerV3 encoder, depending on if the input gives pixels, is a convolutional encoder. The encoder will transform the high dim image into a lower dim *latent representation* (in this case, a discrete, compressed representation; see https://arxiv.org/abs/2312.01203 regarding discrete vs continuous representations). This latent representation is what the RSSM uses. An MLP encoder is used for other kinds of inputs, such as state vectors (e.g., positions, velocities, etc.). Robotics tasks will use both (camera input and state vectors).\n",
    "\n",
    "So initially, I will focus on convolutional encoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9c7eee",
   "metadata": {},
   "source": [
    "A convolutional is basically a learnable filter (its weights). A *filter kernel* slides over the input and computes the dot product at each spatial location. More specifically, in this \"spatial location,\" the kernel computes a dot product between the filter weights and the patch of the input it sits over, giving a value for the whole patch. The goal that is optimized here is whether the dot product is associated with what is wanted, i.e., it basically says \"does this patch look like the filter.\" If yes, the weights will be nudged further because it did accurately capture the patch (change the weights to make the dot product larger). If no, the weights are nudged the other way so the filter stops firing that way (change the weights to make the dot product lower). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8365f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "# code up a basic convolution to get the idea across\n",
    "\n",
    "# example image \n",
    "x = torch.arange(25, dtype=torch.float32).reshape(5,5)\n",
    "\n",
    "# a 3x3 kernel w/ bias\n",
    "# the kernel and bias are learnable parameters\n",
    "kernel = torch.randn(3,3)\n",
    "bias   = torch.randn(1)\n",
    "\n",
    "# output after the kernel (3x3)\n",
    "out_h, out_w = x.shape[0] - 3 + 1, x.shape[1] - 3 + 1\n",
    "out = torch.zeros(out_h, out_w)\n",
    "\n",
    "# basic convolution (no stride, no padding, single channel)\n",
    "for i in range(out_h):\n",
    "    for j in range(out_w):\n",
    "        patch = x[i:i+3, j:j+3] # i+3 and j+3 to make a square of size 3x3\n",
    "        out[i, j] = torch.sum(patch * kernel) + bias # dot product + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc29a2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch implementation\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size, kernel_size))\n",
    "        self.bias   = nn.Parameter(torch.randn(1))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        h, w = x.shape\n",
    "        k = self.weight.shape[0] # k is a hyperparameter (kernel_size)\n",
    "        out_h, out_w = h - k + 1, w - k + 1\n",
    "        out = torch.zeros(out_h, out_w)\n",
    "\n",
    "        for i in range(out_h):\n",
    "            for j in range(out_w):\n",
    "                patch = x[i:i+k, j:j+k]\n",
    "                out[i, j] = torch.sum(patch * self.weight) + self.bias\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3286115d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c8b2e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
