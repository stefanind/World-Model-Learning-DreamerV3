{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a786cc5",
   "metadata": {},
   "source": [
    "### Learning RSSM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e66512",
   "metadata": {},
   "source": [
    "The RSSM is an important part of what makes Dreamer a world model. It helps compress past experiences into a hidden state and predict the future, given some actions. Basically, it tells the agent what the world might look like after taking actions. \n",
    "\n",
    "It is a state-space model, which represents the world as a *latent state* s_t. This is a smaller, more abstract representation of the observation image, i.e., the encoder of the RSSM alters the images' representation into a more compact, abstract encoding. \n",
    "\n",
    "The recurrent structure updates this state over time, while taking into account the history of the past sequence of actions. \n",
    "\n",
    "It also has a prediction abililty. Using the latent state, it will predict the next observation (e.g., make an image by decoding the latent representation), it will predict rewards, and it will predict the next latent state without the need of an observation (this is where its *imagination* rollout happens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a36494f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dffe6b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for manual kl; done in KL_divergence.ipynb\n",
    "def _kl(posterior_logits, prior_logits):\n",
    "    q_log = F.log_softmax(posterior_logits, dim=-1)       # (B, G, C)\n",
    "    p_log = F.log_softmax(prior_logits, dim=-1)           # (B, G, C)\n",
    "    q     = q_log.exp()\n",
    "    kl    = (q * (q_log - p_log)).sum(dim=-1).sum(dim=-1) # (B)\n",
    "    return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b4c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(44)\n",
    "\n",
    "batch_size  = 4\n",
    "num_groups  = 4\n",
    "num_classes = 4\n",
    "X = torch.randn(batch_size, num_groups, num_classes)\n",
    "B, G, C = X.shape\n",
    "\n",
    "# action size depends upon the kind of input\n",
    "# for now, just set to 4\n",
    "size_action        = 4\n",
    "\n",
    "# (1) choose hyperparameters: obs embedding, memory size, stochastic size\n",
    "size_obs_embed     = 64\n",
    "size_hidden        = 128\n",
    "size_stochastic    = num_groups * num_classes # done to properly represent a corresponding output to each class\n",
    "# (2) initialize the action and prev state (deterministic and stochastic)\n",
    "    # need 4 inputs into the whole RSSM cell, only if there is an obs embedding from the encoder; if not, only relies on 'prior' network (imagination step)\n",
    "        # the previous action, the hidden state, the stochastic, and if there is an obs encoding.\n",
    "\n",
    "# create the initial state for hidden and stochastic\n",
    "# these are initialized at the beginning of the RSSM\n",
    "prev_hidden     = torch.zeros(batch_size, size_hidden)\n",
    "prev_stochastic = torch.zeros(batch_size, size_stochastic)\n",
    "\n",
    "# need prev action and an obs embedding\n",
    "# the action depends on what were modelling and the obs embedding depends on the encoder\n",
    "# previous action is initialized to a tensor of zeros -> zeros because of it is neutral and therefore doesn't bias the model\n",
    "prev_action     = torch.zeros(batch_size, size_action)\n",
    "# this always comes from the encoder, so w/o one right now, just use random input\n",
    "obs_embed       = torch.randn(batch_size, size_obs_embed)\n",
    "\n",
    "# (3) feed the inputs into the cell:\n",
    "    # (a) update the GRU memory by feeding in the prev action, prev hidden state, and the prev stochastic \n",
    "        # calculates the update gate (z_t), reset gate (r_t), potential hidden state (h_t_tilda)\n",
    "        # uses these calculation to return the current hidden state h_t\n",
    "            # the hidden state is a summation of how much info from the past and the current states are passed through\n",
    "            # z_t is an addition of both the past and current info being passed through a nonlinearity (sigmoid)\n",
    "                # a z_t closer to 1 says \"pass through all the current info and forget the past\"\n",
    "                # a z_t closer to 0 says \"keep all the info from the past and don't pass through the current info\"\n",
    "            # h_t_tilda takes r_t and multiplies it with the past info; this product is added with the current info\n",
    "                # r_t being 1 says \"use all the past info when calculating the new potential state\"\n",
    "                    # the reset gate determines how much of the past to take into consideration of the new potential state\n",
    "                    # when it is 0, no past info is taken into consideration, only the current input is passed through\n",
    "            # h_t takes z_t and multiplies it and its 1 - z_t against the potential hidden state and the previous state, respectively\n",
    "                # goal: decide how much of the memory and current states are a part of the new hidden state\n",
    "        # so in this context, the GRU is using the prev action, the prev uncertainty (the stochastic), and the prev memory to figure out what the next outcome may likely be.\n",
    "            # i.e., it means \"given what I just did and what I think I am seeing, how should I update my understanding of the situation so I can predict what comes next?\"\"\n",
    "\n",
    "# the previous action and previous stochastic, concatenated along the last dimension \n",
    "gru       = nn.GRUCell(size_stochastic + size_action, size_hidden) \n",
    "gru_input = torch.cat([prev_stochastic, prev_action], dim=-1)\n",
    "hidden_t  = gru(gru_input, prev_hidden)\n",
    "\n",
    "    # (b) calculate the new stochastic with the PRIOR network\n",
    "        # uses the current hidden state calculated by the Gdsadsadsaddsadsadsaddsadsadsadsadsadsadsadsaadsadsaadsadsadits (discrete representation) as (B, G, C)\n",
    "\n",
    "prior_head   = nn.Linear(size_hidden, size_stochastic)\n",
    "prior_logits = prior_head(hidden_t)\n",
    "prior_logits = prior_logits.view(B, G, C)\n",
    "\n",
    "    # (c) if there is an obs, calc the new stochastic with the POSTERIOR network\n",
    "            # calculate the logits from the posterior net (using hidden state and the observation)\n",
    "            # get the one hot vectors for each group using gumbel_softmax, which is the new stochastic\n",
    "                # note: the randomness is injected into the logits in F.gumbel_softmax by adding gumbel noise to the logits\n",
    "            # calculate KL for world model loss\n",
    "                # measures how much the prior network's distribution differs from the posterior network's distribution\n",
    "                # goal: want to adjust the prior network's weights to align more closely with posterior \n",
    "                # reason: posterior utilizes the observation in training but the prior doesn't\n",
    "                # so we want to adjust the prior to be closer to the posterior\n",
    "        # if no obs, then use the stochastic from the PRIOR network (imagination run)\n",
    "            # get logits and one hot vectors only using prior\n",
    "            # return the new stochastic from the onehots \n",
    "\n",
    "\n",
    "\n",
    "postr_head = nn.Linear(size_hidden + size_obs_embed, size_stochastic)\n",
    "if obs_embed is not None:\n",
    "    # get postr network logits\n",
    "    joined       = torch.cat([hidden_t, obs_embed], dim=-1)\n",
    "    postr_logits = postr_head(joined)\n",
    "    postr_logits = postr_logits.view(B, G, C)\n",
    "\n",
    "    # get stochastic using gumbel\n",
    "    # reshape to (B * G, C) because want to say that each row is independent\n",
    "    postr_logits_gumbel = postr_logits.view(B * G, C)\n",
    "    onehots = F.gumbel_softmax(postr_logits_gumbel, tau=0.8, dim=-1, hard=True) # tau is gradually decayed per training step, but leave it for now\n",
    "    stochastic_t = onehots.view(B, G * C)\n",
    "\n",
    "    # get kl for world model loss\n",
    "    kl = _kl(postr_logits, prior_logits)\n",
    "\n",
    "else:\n",
    "    prior_logits_gumbel = prior_logits.view(B * G, C)\n",
    "    onehots = F.gumbel_softmax(prior_logits_gumbel, tau=0.8, dim=-1, hard=True)\n",
    "    stochastic_t = onehots.view(B, G * C)\n",
    "\n",
    "    # (d) return the new hidden state and the distribution associated with the stochastic\n",
    "\n",
    "new_state = (hidden_t, stochastic_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14a6c6c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 128]), torch.Size([4, 16]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_state[0].shape, new_state[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ab0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# DreamerV3 separates the RSSM into three parts: (1) Encoder, (2) Sequence Model, (3) Dynamics Predictor\n",
    "# Sequence Model: \n",
    "    # \"a sequence model with recurrent state ht predicts the sequence of these representations given past actions at−1.\"\n",
    "    # ht = fϕ(ht−1, zt−1, at−1)\n",
    "    # inputs the prev hidden state, prev stochastic state, prev action\n",
    "    # outputs the hidden state\n",
    "    # gated recurrent unit does this operation of producing the hidden state\n",
    "    # \"The sequence model is a GRU with block-diagonal recurrent weights of 8 blocks to allow for a large number of memory units without quadratic increase in parameters and FLOPs\"\n",
    "    # \"The input to the GRU at each time step is a linear embedding of the sampled latent zt, of the action at, and of the recurrent state to allow mixing between blocks.\"\n",
    "\n",
    "class SequenceModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, size_stochastic, size_action, size_hidden, embed_dim, num_blocks=8):\n",
    "        super().__init__()\n",
    "\n",
    "        assert size_hidden % num_blocks == 0\n",
    "\n",
    "\n",
    "        self.embed_dim       = embed_dim\n",
    "        self.block_size      = size_hidden // num_blocks\n",
    "        self.size_stochastic = size_stochastic\n",
    "        self.size_action     = size_action\n",
    "        self.size_hidden     = size_hidden\n",
    "\n",
    "\n",
    "        self.embed_z = nn.Linear(size_stochastic, embed_dim)\n",
    "        self.embed_a = nn.Linear(size_action,     embed_dim)\n",
    "        self.embed_h = nn.Linear(size_hidden,     embed_dim)\n",
    "\n",
    "        self.gru_blocks = nn.ModuleList([\n",
    "            nn.GRUCell(embed_dim, self.block_size) for _ in range(num_blocks)\n",
    "        ])\n",
    "\n",
    "\n",
    "    def forward(self, prev_hidden, prev_stochastic, prev_action):\n",
    "        x_t = self.embed_a(prev_action) + self.embed_h(prev_hidden) + self.embed_z(prev_stochastic)\n",
    "        x_t = F.elu(x_t) # e\n",
    "\n",
    "        h_slices = []\n",
    "        for i, cell in enumerate(self.gru_blocks):\n",
    "            start    = i * self.block_size\n",
    "            end      = (i + 1) * self.block_size\n",
    "            h_prev_i = prev_hidden[:, start:end]\n",
    "            h_i      = cell(x_t, h_prev_i)\n",
    "            h_slices.append(h_i)\n",
    "        h_t = torch.cat(h_slices, dim=-1)\n",
    "        \n",
    "        return h_t\n",
    "\n",
    "\n",
    "# Dynamics Predictor:\n",
    "    # zˆt ∼ pϕ(ˆzt | ht)\n",
    "    # given the current hidden state, outputs the distribution of the stochastic latent\n",
    "        # prior network gives the prediction based on no observational input\n",
    "\n",
    "class DynamicsPredictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, size_hidden, num_groups, num_classes, tau_init=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.G = num_groups\n",
    "        self.C = num_classes\n",
    "        self.size_stochastic = num_groups * num_classes\n",
    "        self.tau = tau_init\n",
    "\n",
    "        self.prior = nn.Linear(size_hidden, self.size_stochastic)\n",
    "\n",
    "    def dist(self, h_t): \n",
    "        B = h_t.size(0)\n",
    "        logits = self.prior(h_t)\n",
    "        logits = logits.view(B, self.G, self.C)\n",
    "        return logits\n",
    "    \n",
    "    def sample(self, logits, hard=True):\n",
    "        onehots = F.gumbel_softmax(logits, hard=hard, tau=self.tau, dim=-1)\n",
    "        z_t = onehots.view(B, self.G * self.C)\n",
    "        return logits, z_t\n",
    "\n",
    "# Encoder:\n",
    "    # \"an encoder maps sensory inputs xt to stochastic representations zt.\"\n",
    "    # zt ∼ qϕ(zt | ht, xt)\n",
    "    # given the hidden state and observational input, output the distribution of the stochastic latent\n",
    "        # posterior network gives this output\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, size_obs_embed, size_hidden, num_groups, num_classes, tau_init=1.0):\n",
    "        super().__init__()\n",
    "        self.G = num_groups\n",
    "        self.C = num_classes\n",
    "        self.size_stochastic = num_groups * num_classes\n",
    "        self.tau = tau_init\n",
    "\n",
    "        self.postr = nn.Linear(size_hidden + size_obs_embed, self.size_stochastic)\n",
    "\n",
    "    def dist(self, x_t, h_t):\n",
    "        B = x_t.size(0)\n",
    "        joined = torch.cat([h_t, x_t], dim=-1)\n",
    "        logits = self.postr(joined)\n",
    "        logits = logits.view(B, self.G, self.C)\n",
    "        return logits\n",
    "\n",
    "    def forward(self, logits, hard=True):\n",
    "        onehots = F.gumbel_softmax(logits, tau=self.tau, hard=hard, dim=-1)\n",
    "        z_t = onehots.view(B, self.G * self.C) \n",
    "        return z_t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a04c6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
